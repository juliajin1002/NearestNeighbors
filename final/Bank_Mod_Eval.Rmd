---
title: "Bank_Mod_Eval"
author: "Julia Jin"
date: "12/5/2021"
output: html_document
---
```{r init, include=F}
# The package "ezids" (EZ Intro to Data Science) includes a lot of the helper functions we developed for the course. 
# Some of the frequently used functions are loadPkg(), xkabledply(), xkablesummary(), uzscale(), etc.
# Once installed, load the library.
library(ezids)
library(dplyr)
library(ggplot2)
library(modeest)
library(ggeasy)
library(skimr)
library(janitor)
```

```{r setup, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
```
# Bank Model
## The beginning

```{r initial_data}
bank <- read_csv(file="bank.csv")
```

```{r change_data_type}
# changing the data types 
bank[] <- lapply(bank, as.factor)
bank$age <- as.numeric(bank$age)
bank$balance <- as.numeric(bank$balance)
bank$day <- as.numeric(bank$day)
bank$duration <- as.numeric(bank$duration)
bank$campaign <- as.numeric(bank$campaign)
bank$previous <- as.numeric(bank$previous)
bank$pdays <- as.numeric(bank$pdays)
```

```{r remove_outliers}
bank2 = outlierKD2(bank, age, rm=T, histogram = F)
```

## Data Partition

```{r}
library(dominanceanalysis)
library(caTools)
set.seed(123)
sample <- sample.split(bank2$y, SplitRatio = 0.7)
train <- subset(bank2, sample == TRUE)
test  <- subset(bank2, sample == FALSE)
```

## Model Construction before balancing
```{r model}
mybanklog <- glm(y ~ age+marital+education+default+balance+housing+loan+contact+duration+campaign+pdays+previous+poutcome, data = train, family = "binomial")
summary(mybanklog)
```

```{r model_refine}
mybanklog2 <- glm(y ~ balance+housing+loan+duration+campaign, data = train, family = "binomial")
summary(mybanklog2)
```

Interpret the table of null deviance.
```{r anova}
anova(mybanklog2, test="Chisq")
```

Look at the McFadden value.
```{r McF}
library(pscl)
pR2(mybanklog2)
```

## Predictors importance using dominance analysis
```{r da}
dabank <- dominanceAnalysis(mybanklog2)
```

Explore the raw values of each fit index by using getFits(). For simplicity, we only consider the McFadden index, R2M.
```{r}
getFits(dabank,"r2.m")
```

The first row represents the raw values of each univariate model. The following rows show the additional contribution of each predictor added to the subset model (indicated by the first column).

### complete dominance matrix
```{r}
dominanceMatrix(dabank, type="complete",fit.functions = "r2.m", ordered=TRUE)
```

This complete dominance matrix summarizes the relation between each pair of predictors.

### Contribution by level
```{r}
contributionByLevel(dabank, fit.functions="r2.m")
```

For each model size (see column level of the table), the average additional contribution of each predictor is calculated.

Here is a graph of contribution by levels.
```{r}
plot(dabank, which.graph ="conditional",fit.function = "r2.m")
```

### Conditional dominance
```{r}
dominanceMatrix(dabank, type="conditional",fit.functions = "r2.m", ordered=TRUE)
```

### General dominance
```{r}
averageContribution(dabank,fit.functions = "r2.m")
```

```{r}
plot(dabank, which.graph ="general",fit.function = "r2.m")
```

To determine general dominance, we compute the mean of each predictor’s conditional measures.
```{r}
dominanceMatrix(dabank, type="general",fit.functions = "r2.m", ordered=TRUE)
```

## predicting before balancing 
```{r}
library(pROC)
banklogpred <- predict(mybanklog2, newdata = test, type = "response")
```

# Balance the dataset
```{r}
#install.packages("ROSE")
library(ROSE)
bank_balanced_over <- ovun.sample(y ~., data = train, method = "over", N = 5600)$data
table(bank_balanced_over$y)
```

```{r}
# using balanced dataset
mybanklog2b <- glm(y ~ balance+housing+loan+duration+campaign, data = bank_balanced_over, family = "binomial")
summary(mybanklog2b)
```
```{r}
library(ggthemes)
# prediction
train$prediction <- predict(mybanklog2b, newdata = train, type = "response" )
test$prediction  <- predict(mybanklog2b, newdata = test , type = "response" )

# distribution of the prediction score grouped by known outcome
ggplot( train, aes( prediction, color = as.factor(y) ) ) + 
geom_density( size = 1 ) +
ggtitle( "Training Set's Predicted Score" ) + 
scale_color_economist( name = "data", labels = c( "negative", "positive" ) ) + 
theme_economist()
```
# Reference
Exploring predictors’ importance in binomial logistic regressions https://cran.r-project.org/web/packages/dominanceanalysis/vignettes/da-logistic-regression.html